// AUTOGENERATED BY storj.io/dbx
// DO NOT EDIT.

package paged_composite

import (
	"bytes"
	"context"
	"database/sql"
	"errors"
	"fmt"
	"reflect"
	"strconv"
	"strings"
	"sync"
	"time"
	"unicode"

	"cloud.google.com/go/spanner"
	"crypto/rand"
	"encoding/base64"
	"encoding/json"
	_ "github.com/googleapis/go-sql-spanner"
	"github.com/jackc/pgx/v5/pgconn"
	_ "github.com/jackc/pgx/v5/stdlib"
	"github.com/mattn/go-sqlite3"
	"google.golang.org/grpc/codes"
)

// Prevent conditional imports from causing build failures.
var _ = strconv.Itoa
var _ = strings.LastIndex
var _ = fmt.Sprint
var _ sync.Mutex

var (
	WrapErr     = func(err *Error) error { return err }
	Logger      func(format string, args ...any)
	ShouldRetry func(driver string, err error) bool

	errTooManyRows       = errors.New("too many rows")
	errUnsupportedDriver = errors.New("unsupported driver")
	errEmptyUpdate       = errors.New("empty update")
)

func logError(format string, args ...any) {
	if Logger != nil {
		Logger(format, args...)
	}
}

type ErrorCode int

const (
	ErrorCode_Unknown ErrorCode = iota
	ErrorCode_UnsupportedDriver
	ErrorCode_NoRows
	ErrorCode_TxDone
	ErrorCode_TooManyRows
	ErrorCode_ConstraintViolation
	ErrorCode_EmptyUpdate
)

type Error struct {
	Err         error
	Code        ErrorCode
	Driver      string
	Constraint  string
	QuerySuffix string
}

func (e *Error) Error() string {
	return e.Err.Error()
}

func (e *Error) Unwrap() error {
	return e.Err
}

func wrapErr(e *Error) error {
	if WrapErr == nil {
		return e
	}
	return WrapErr(e)
}

func makeErr(err error) error {
	if err == nil {
		return nil
	}
	var e *Error
	if errors.As(err, &e) {
		return wrapErr(e)
	}
	e = &Error{Err: err}
	switch {
	case errors.Is(err, sql.ErrNoRows):
		e.Code = ErrorCode_NoRows
	case errors.Is(err, sql.ErrTxDone):
		e.Code = ErrorCode_TxDone
	}
	return wrapErr(e)
}

func shouldRetry(driver string, err error) bool {
	if ShouldRetry == nil {
		return false
	}
	return ShouldRetry(driver, err)
}

func unsupportedDriver(driver string) error {
	return wrapErr(&Error{
		Err:    errUnsupportedDriver,
		Code:   ErrorCode_UnsupportedDriver,
		Driver: driver,
	})
}

func emptyUpdate() error {
	return wrapErr(&Error{
		Err:  errEmptyUpdate,
		Code: ErrorCode_EmptyUpdate,
	})
}

func tooManyRows(query_suffix string) error {
	return wrapErr(&Error{
		Err:         errTooManyRows,
		Code:        ErrorCode_TooManyRows,
		QuerySuffix: query_suffix,
	})
}

func constraintViolation(err error, constraint string) error {
	return wrapErr(&Error{
		Err:        err,
		Code:       ErrorCode_ConstraintViolation,
		Constraint: constraint,
	})
}

type driver interface {
	ExecContext(ctx context.Context, query string, args ...any) (sql.Result, error)
	QueryContext(ctx context.Context, query string, args ...any) (*sql.Rows, error)
	QueryRowContext(ctx context.Context, query string, args ...any) *sql.Row
}

type DB struct {
	*sql.DB
	dbMethods

	Hooks struct {
		Now func() time.Time
	}

	driver string
}

func Open(driver, source string) (db *DB, err error) {
	var sql_db *sql.DB
	switch driver {
	case "sqlite3":
		sql_db, err = opensqlite3(source)
	case "pgx":
		sql_db, err = openpgx(source)
	case "pgxcockroach":
		sql_db, err = openpgxcockroach(source)
	case "spanner":
		sql_db, err = openspanner(source)
	default:
		return nil, unsupportedDriver(driver)
	}
	if err != nil {
		return nil, makeErr(err)
	}
	defer func(sql_db *sql.DB) {
		if err != nil {
			_ = sql_db.Close()
		}
	}(sql_db)

	if err := sql_db.Ping(); err != nil {
		return nil, makeErr(err)
	}

	db = &DB{
		DB: sql_db,

		driver: driver,
	}
	db.Hooks.Now = time.Now

	switch driver {
	case "sqlite3":
		db.dbMethods = newsqlite3(db)
	case "pgx":
		db.dbMethods = newpgx(db)
	case "pgxcockroach":
		db.dbMethods = newpgxcockroach(db)
	case "spanner":
		db.dbMethods = newspanner(db)
	default:
		return nil, unsupportedDriver(driver)
	}

	return db, nil
}

func (obj *DB) Close() (err error) {
	return obj.makeErr(obj.DB.Close())
}

func (obj *DB) Open(ctx context.Context) (*Tx, error) {
	tx, err := obj.DB.BeginTx(ctx, nil)
	if err != nil {
		return nil, obj.makeErr(err)
	}

	return &Tx{
		Tx:        tx,
		txMethods: obj.wrapTx(tx),
	}, nil
}

func DeleteAll(ctx context.Context, db *DB) (int64, error) {
	tx, err := db.Open(ctx)
	if err != nil {
		return 0, err
	}
	defer func() {
		if err == nil {
			err = db.makeErr(tx.Commit())
			return
		}

		if err_rollback := tx.Rollback(); err_rollback != nil {
			logError("delete-all: rollback failed: %v", db.makeErr(err_rollback))
		}
	}()
	return tx.deleteAll(ctx)
}

type Tx struct {
	Tx *sql.Tx
	txMethods
}

func (tx *Tx) ExecContext(ctx context.Context, query string, args ...any) (sql.Result, error) {
	return tx.Tx.ExecContext(ctx, query, args...)
}
func (tx *Tx) QueryContext(ctx context.Context, query string, args ...any) (*sql.Rows, error) {
	return tx.Tx.QueryContext(ctx, query, args...)
}
func (tx *Tx) QueryRowContext(ctx context.Context, query string, args ...any) *sql.Row {
	return tx.Tx.QueryRowContext(ctx, query, args...)
}

type dialectTx struct {
	tx *sql.Tx
}

func (tx *dialectTx) Commit() (err error) {
	return makeErr(tx.tx.Commit())
}

func (tx *dialectTx) Rollback() (err error) {
	return makeErr(tx.tx.Rollback())
}

type sqlite3Impl struct {
	db      *DB
	dialect __sqlbundle_sqlite3
	driver  driver
	txn     bool
}

func (obj *sqlite3Impl) Rebind(s string) string {
	return obj.dialect.Rebind(s)
}

func (obj *sqlite3Impl) logStmt(stmt string, args ...any) {
	sqlite3LogStmt(stmt, args...)
}

func (obj *sqlite3Impl) makeErr(err error) error {
	constraint, ok := obj.isConstraintError(err)
	if ok {
		return constraintViolation(err, constraint)
	}
	return makeErr(err)
}

func (obj *sqlite3Impl) shouldRetry(err error) bool {
	return !obj.txn && shouldRetry(obj.db.driver, err)
}

type sqlite3Impl_retryingRow struct {
	obj   *sqlite3Impl
	ctx   context.Context
	query string
	args  []any
}

func (obj *sqlite3Impl) queryRowContext(ctx context.Context, query string, args ...any) *sqlite3Impl_retryingRow {
	return &sqlite3Impl_retryingRow{
		obj:   obj,
		ctx:   ctx,
		query: query,
		args:  args,
	}
}

func (rows *sqlite3Impl_retryingRow) Scan(dest ...any) error {
	for {
		err := rows.obj.driver.QueryRowContext(rows.ctx, rows.query, rows.args...).Scan(dest...)
		if err != nil {
			if rows.obj.shouldRetry(err) {
				continue
			}
			// caller will wrap this error
			return err
		}
		return nil
	}
}

type sqlite3DB struct {
	db *DB
	*sqlite3Impl
}

func newsqlite3(db *DB) *sqlite3DB {
	return &sqlite3DB{
		db: db,
		sqlite3Impl: &sqlite3Impl{
			db:     db,
			driver: db.DB,
		},
	}
}

func (obj *sqlite3DB) Schema() []string {
	return []string{

		`CREATE TABLE consumed_serials (
	expires_at TIMESTAMP NOT NULL,
	storage_node_id BLOB NOT NULL,
	project_id BLOB NOT NULL,
	bucket_name BLOB NOT NULL,
	action INTEGER NOT NULL,
	serial_number BLOB NOT NULL,
	settled INTEGER NOT NULL,
	PRIMARY KEY ( expires_at, storage_node_id, project_id, bucket_name, action, serial_number )
)`,
	}
}

func (obj *sqlite3DB) DropSchema() []string {
	return []string{

		`DROP TABLE IF EXISTS consumed_serials`,
	}
}

func (obj *sqlite3DB) wrapTx(tx *sql.Tx) txMethods {
	return &sqlite3Tx{
		dialectTx: dialectTx{tx: tx},
		sqlite3Impl: &sqlite3Impl{
			db:     obj.db,
			driver: tx,
			txn:    true,
		},
	}
}

type sqlite3Tx struct {
	dialectTx
	*sqlite3Impl
}

func sqlite3LogStmt(stmt string, args ...any) {
	// TODO: render placeholders
	if Logger != nil {
		out := fmt.Sprintf("stmt: %s\nargs: %v\n", stmt, pretty(args))
		Logger(out)
	}
}

type pgxImpl struct {
	db      *DB
	dialect __sqlbundle_pgx
	driver  driver
	txn     bool
}

func (obj *pgxImpl) Rebind(s string) string {
	return obj.dialect.Rebind(s)
}

func (obj *pgxImpl) logStmt(stmt string, args ...any) {
	pgxLogStmt(stmt, args...)
}

func (obj *pgxImpl) makeErr(err error) error {
	constraint, ok := obj.isConstraintError(err)
	if ok {
		return constraintViolation(err, constraint)
	}
	return makeErr(err)
}

func (obj *pgxImpl) shouldRetry(err error) bool {
	return !obj.txn && shouldRetry(obj.db.driver, err)
}

type pgxImpl_retryingRow struct {
	obj   *pgxImpl
	ctx   context.Context
	query string
	args  []any
}

func (obj *pgxImpl) queryRowContext(ctx context.Context, query string, args ...any) *pgxImpl_retryingRow {
	return &pgxImpl_retryingRow{
		obj:   obj,
		ctx:   ctx,
		query: query,
		args:  args,
	}
}

func (rows *pgxImpl_retryingRow) Scan(dest ...any) error {
	for {
		err := rows.obj.driver.QueryRowContext(rows.ctx, rows.query, rows.args...).Scan(dest...)
		if err != nil {
			if rows.obj.shouldRetry(err) {
				continue
			}
			// caller will wrap this error
			return err
		}
		return nil
	}
}

type pgxDB struct {
	db *DB
	*pgxImpl
}

func newpgx(db *DB) *pgxDB {
	return &pgxDB{
		db: db,
		pgxImpl: &pgxImpl{
			db:     db,
			driver: db.DB,
		},
	}
}

func (obj *pgxDB) Schema() []string {
	return []string{

		`CREATE TABLE consumed_serials (
	expires_at timestamp NOT NULL,
	storage_node_id bytea NOT NULL,
	project_id bytea NOT NULL,
	bucket_name bytea NOT NULL,
	action integer NOT NULL,
	serial_number bytea NOT NULL,
	settled bigint NOT NULL,
	PRIMARY KEY ( expires_at, storage_node_id, project_id, bucket_name, action, serial_number )
)`,
	}
}

func (obj *pgxDB) DropSchema() []string {
	return []string{

		`DROP TABLE IF EXISTS consumed_serials`,
	}
}

func (obj *pgxDB) wrapTx(tx *sql.Tx) txMethods {
	return &pgxTx{
		dialectTx: dialectTx{tx: tx},
		pgxImpl: &pgxImpl{
			db:     obj.db,
			driver: tx,
			txn:    true,
		},
	}
}

type pgxTx struct {
	dialectTx
	*pgxImpl
}

func pgxLogStmt(stmt string, args ...any) {
	// TODO: render placeholders
	if Logger != nil {
		out := fmt.Sprintf("stmt: %s\nargs: %v\n", stmt, pretty(args))
		Logger(out)
	}
}

type pgxcockroachImpl struct {
	db      *DB
	dialect __sqlbundle_pgxcockroach
	driver  driver
	txn     bool
}

func (obj *pgxcockroachImpl) Rebind(s string) string {
	return obj.dialect.Rebind(s)
}

func (obj *pgxcockroachImpl) logStmt(stmt string, args ...any) {
	pgxcockroachLogStmt(stmt, args...)
}

func (obj *pgxcockroachImpl) makeErr(err error) error {
	constraint, ok := obj.isConstraintError(err)
	if ok {
		return constraintViolation(err, constraint)
	}
	return makeErr(err)
}

func (obj *pgxcockroachImpl) shouldRetry(err error) bool {
	return !obj.txn && shouldRetry(obj.db.driver, err)
}

type pgxcockroachImpl_retryingRow struct {
	obj   *pgxcockroachImpl
	ctx   context.Context
	query string
	args  []any
}

func (obj *pgxcockroachImpl) queryRowContext(ctx context.Context, query string, args ...any) *pgxcockroachImpl_retryingRow {
	return &pgxcockroachImpl_retryingRow{
		obj:   obj,
		ctx:   ctx,
		query: query,
		args:  args,
	}
}

func (rows *pgxcockroachImpl_retryingRow) Scan(dest ...any) error {
	for {
		err := rows.obj.driver.QueryRowContext(rows.ctx, rows.query, rows.args...).Scan(dest...)
		if err != nil {
			if rows.obj.shouldRetry(err) {
				continue
			}
			// caller will wrap this error
			return err
		}
		return nil
	}
}

type pgxcockroachDB struct {
	db *DB
	*pgxcockroachImpl
}

func newpgxcockroach(db *DB) *pgxcockroachDB {
	return &pgxcockroachDB{
		db: db,
		pgxcockroachImpl: &pgxcockroachImpl{
			db:     db,
			driver: db.DB,
		},
	}
}

func (obj *pgxcockroachDB) Schema() []string {
	return []string{

		`CREATE TABLE consumed_serials (
	expires_at timestamp NOT NULL,
	storage_node_id bytea NOT NULL,
	project_id bytea NOT NULL,
	bucket_name bytea NOT NULL,
	action integer NOT NULL,
	serial_number bytea NOT NULL,
	settled bigint NOT NULL,
	PRIMARY KEY ( expires_at, storage_node_id, project_id, bucket_name, action, serial_number )
)`,
	}
}

func (obj *pgxcockroachDB) DropSchema() []string {
	return []string{

		`DROP TABLE IF EXISTS consumed_serials`,
	}
}

func (obj *pgxcockroachDB) wrapTx(tx *sql.Tx) txMethods {
	return &pgxcockroachTx{
		dialectTx: dialectTx{tx: tx},
		pgxcockroachImpl: &pgxcockroachImpl{
			db:     obj.db,
			driver: tx,
			txn:    true,
		},
	}
}

type pgxcockroachTx struct {
	dialectTx
	*pgxcockroachImpl
}

func pgxcockroachLogStmt(stmt string, args ...any) {
	// TODO: render placeholders
	if Logger != nil {
		out := fmt.Sprintf("stmt: %s\nargs: %v\n", stmt, pretty(args))
		Logger(out)
	}
}

type spannerImpl struct {
	db      *DB
	dialect __sqlbundle_spanner
	driver  driver
	txn     bool
}

func (obj *spannerImpl) Rebind(s string) string {
	return obj.dialect.Rebind(s)
}

func (obj *spannerImpl) logStmt(stmt string, args ...any) {
	spannerLogStmt(stmt, args...)
}

func (obj *spannerImpl) makeErr(err error) error {
	constraint, ok := obj.isConstraintError(err)
	if ok {
		return constraintViolation(err, constraint)
	}
	return makeErr(err)
}

func (obj *spannerImpl) shouldRetry(err error) bool {
	return !obj.txn && shouldRetry(obj.db.driver, err)
}

type spannerImpl_retryingRow struct {
	obj   *spannerImpl
	ctx   context.Context
	query string
	args  []any
}

func (obj *spannerImpl) queryRowContext(ctx context.Context, query string, args ...any) *spannerImpl_retryingRow {
	return &spannerImpl_retryingRow{
		obj:   obj,
		ctx:   ctx,
		query: query,
		args:  args,
	}
}

func (rows *spannerImpl_retryingRow) Scan(dest ...any) error {
	for {
		err := rows.obj.driver.QueryRowContext(rows.ctx, rows.query, rows.args...).Scan(dest...)
		if err != nil {
			if rows.obj.shouldRetry(err) {
				continue
			}
			// caller will wrap this error
			return err
		}
		return nil
	}
}

type spannerDB struct {
	db *DB
	*spannerImpl
}

func newspanner(db *DB) *spannerDB {
	return &spannerDB{
		db: db,
		spannerImpl: &spannerImpl{
			db:     db,
			driver: db.DB,
		},
	}
}

func (obj *spannerDB) Schema() []string {
	return []string{

		`CREATE TABLE consumed_serials (
	expires_at TIMESTAMP NOT NULL,
	storage_node_id BYTES(MAX) NOT NULL,
	project_id BYTES(MAX) NOT NULL,
	bucket_name BYTES(MAX) NOT NULL,
	action INT64 NOT NULL,
	serial_number BYTES(MAX) NOT NULL,
	settled INT64 NOT NULL
) PRIMARY KEY ( expires_at, storage_node_id, project_id, bucket_name, action, serial_number )`,
	}
}

func (obj *spannerDB) DropSchema() []string {
	return []string{

		`ALTER TABLE  consumed_serials ALTER expires_at SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS consumed_serials_expires_at`,

		`ALTER TABLE  consumed_serials ALTER storage_node_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS consumed_serials_storage_node_id`,

		`ALTER TABLE  consumed_serials ALTER project_id SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS consumed_serials_project_id`,

		`ALTER TABLE  consumed_serials ALTER bucket_name SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS consumed_serials_bucket_name`,

		`ALTER TABLE  consumed_serials ALTER action SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS consumed_serials_action`,

		`ALTER TABLE  consumed_serials ALTER serial_number SET DEFAULT (null)`,

		`DROP SEQUENCE IF EXISTS consumed_serials_serial_number`,

		`DROP TABLE IF EXISTS consumed_serials`,
	}
}

func (obj *spannerDB) wrapTx(tx *sql.Tx) txMethods {
	return &spannerTx{
		dialectTx: dialectTx{tx: tx},
		spannerImpl: &spannerImpl{
			db:     obj.db,
			driver: tx,
			txn:    true,
		},
	}
}

type spannerTx struct {
	dialectTx
	*spannerImpl
}

func spannerLogStmt(stmt string, args ...any) {
	// TODO: render placeholders
	if Logger != nil {
		out := fmt.Sprintf("stmt: %s\nargs: %v\n", stmt, pretty(args))
		Logger(out)
	}
}

type pretty []any

func (p pretty) Format(f fmt.State, c rune) {
	_, _ = fmt.Fprint(f, "[")
nextval:
	for i, val := range p {
		if i > 0 {
			_, _ = fmt.Fprint(f, ", ")
		}
		rv := reflect.ValueOf(val)
		if rv.Kind() == reflect.Ptr {
			if rv.IsNil() {
				_, _ = fmt.Fprint(f, "NULL")
				continue
			}
			val = rv.Elem().Interface()
		}
		switch v := val.(type) {
		case string:
			_, _ = fmt.Fprintf(f, "%q", v)
		case time.Time:
			_, _ = fmt.Fprintf(f, "%s", v.Format(time.RFC3339Nano))
		case []byte:
			for _, b := range v {
				if !unicode.IsPrint(rune(b)) {
					_, _ = fmt.Fprintf(f, "%#x", v)
					continue nextval
				}
			}
			_, _ = fmt.Fprintf(f, "%q", v)
		default:
			_, _ = fmt.Fprintf(f, "%v", v)
		}
	}
	_, _ = fmt.Fprint(f, "]")
}

type ConsumedSerial struct {
	ExpiresAt     time.Time
	StorageNodeId []byte
	ProjectId     []byte
	BucketName    []byte
	Action        uint
	SerialNumber  []byte
	Settled       uint64
}

func (ConsumedSerial) _Table() string { return "consumed_serials" }

type ConsumedSerial_Update_Fields struct {
}

type ConsumedSerial_ExpiresAt_Field struct {
	_set   bool
	_null  bool
	_value time.Time
}

func ConsumedSerial_ExpiresAt(v time.Time) ConsumedSerial_ExpiresAt_Field {
	v = toUTC(v)
	return ConsumedSerial_ExpiresAt_Field{_set: true, _value: v}
}

func (f ConsumedSerial_ExpiresAt_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ConsumedSerial_StorageNodeId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ConsumedSerial_StorageNodeId(v []byte) ConsumedSerial_StorageNodeId_Field {
	return ConsumedSerial_StorageNodeId_Field{_set: true, _value: v}
}

func (f ConsumedSerial_StorageNodeId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ConsumedSerial_ProjectId_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ConsumedSerial_ProjectId(v []byte) ConsumedSerial_ProjectId_Field {
	return ConsumedSerial_ProjectId_Field{_set: true, _value: v}
}

func (f ConsumedSerial_ProjectId_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ConsumedSerial_BucketName_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ConsumedSerial_BucketName(v []byte) ConsumedSerial_BucketName_Field {
	return ConsumedSerial_BucketName_Field{_set: true, _value: v}
}

func (f ConsumedSerial_BucketName_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ConsumedSerial_Action_Field struct {
	_set   bool
	_null  bool
	_value uint
}

func ConsumedSerial_Action(v uint) ConsumedSerial_Action_Field {
	return ConsumedSerial_Action_Field{_set: true, _value: v}
}

func (f ConsumedSerial_Action_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ConsumedSerial_SerialNumber_Field struct {
	_set   bool
	_null  bool
	_value []byte
}

func ConsumedSerial_SerialNumber(v []byte) ConsumedSerial_SerialNumber_Field {
	return ConsumedSerial_SerialNumber_Field{_set: true, _value: v}
}

func (f ConsumedSerial_SerialNumber_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

type ConsumedSerial_Settled_Field struct {
	_set   bool
	_null  bool
	_value uint64
}

func ConsumedSerial_Settled(v uint64) ConsumedSerial_Settled_Field {
	return ConsumedSerial_Settled_Field{_set: true, _value: v}
}

func (f ConsumedSerial_Settled_Field) value() any {
	if !f._set || f._null {
		return nil
	}
	return f._value
}

func toUTC(t time.Time) time.Time {
	return t.UTC()
}

func toDate(t time.Time) time.Time {
	// keep up the minute portion so that translations between timezones will
	// continue to reflect properly.
	return t.Truncate(time.Minute)
}

//
// runtime support for building sql statements
//

type __sqlbundle_SQL interface {
	Render() string

	private()
}

type __sqlbundle_Dialect interface {
	// Rebind gives the opportunity to rewrite provided SQL into a SQL dialect.
	Rebind(sql string) string
}

type __sqlbundle_RenderOp int

const (
	__sqlbundle_NoFlatten __sqlbundle_RenderOp = iota
	__sqlbundle_NoTerminate
)

func __sqlbundle_RenderAll(dialect __sqlbundle_Dialect, sqls []__sqlbundle_SQL, ops ...__sqlbundle_RenderOp) []string {
	var rs []string
	for _, sql := range sqls {
		rs = append(rs, __sqlbundle_Render(dialect, sql, ops...))
	}
	return rs
}

func __sqlbundle_Render(dialect __sqlbundle_Dialect, sql __sqlbundle_SQL, ops ...__sqlbundle_RenderOp) string {
	out := sql.Render()

	flatten := true
	terminate := true
	for _, op := range ops {
		switch op {
		case __sqlbundle_NoFlatten:
			flatten = false
		case __sqlbundle_NoTerminate:
			terminate = false
		}
	}

	if flatten {
		out = __sqlbundle_flattenSQL(out)
	}
	if terminate {
		out += ";"
	}

	return dialect.Rebind(out)
}

func __sqlbundle_flattenSQL(x string) string {
	// trim whitespace from beginning and end
	s, e := 0, len(x)-1
	for s < len(x) && (x[s] == ' ' || x[s] == '\t' || x[s] == '\n') {
		s++
	}
	for s <= e && (x[e] == ' ' || x[e] == '\t' || x[e] == '\n') {
		e--
	}
	if s > e {
		return ""
	}
	x = x[s : e+1]

	// check for whitespace that needs fixing
	wasSpace := false
	for i := 0; i < len(x); i++ {
		r := x[i]
		justSpace := r == ' '
		if (wasSpace && justSpace) || r == '\t' || r == '\n' {
			// whitespace detected, start writing a new string
			var result strings.Builder
			result.Grow(len(x))
			if wasSpace {
				result.WriteString(x[:i-1])
			} else {
				result.WriteString(x[:i])
			}
			for p := i; p < len(x); p++ {
				for p < len(x) && (x[p] == ' ' || x[p] == '\t' || x[p] == '\n') {
					p++
				}
				result.WriteByte(' ')

				start := p
				for p < len(x) && !(x[p] == ' ' || x[p] == '\t' || x[p] == '\n') {
					p++
				}
				result.WriteString(x[start:p])
			}

			return result.String()
		}
		wasSpace = justSpace
	}

	// no problematic whitespace found
	return x
}

// this type is specially named to match up with the name returned by the
// dialect impl in the sql package.
type __sqlbundle_cockroach struct{}

func (p __sqlbundle_cockroach) Rebind(sql string) string {
	return __sqlbundle_postgres{}.Rebind(sql)
}

// this type is specially named to match up with the name returned by the
// dialect impl in the sql package.
type __sqlbundle_pgx struct{}

func (p __sqlbundle_pgx) Rebind(sql string) string {
	return __sqlbundle_postgres{}.Rebind(sql)
}

// this type is specially named to match up with the name returned by the
// dialect impl in the sql package.
type __sqlbundle_pgxcockroach struct{}

func (p __sqlbundle_pgxcockroach) Rebind(sql string) string {
	return __sqlbundle_postgres{}.Rebind(sql)
}

// this type is specially named to match up with the name returned by the
// dialect impl in the sql package.
type __sqlbundle_postgres struct{}

func (p __sqlbundle_postgres) Rebind(sql string) string {
	type sqlParseState int
	const (
		sqlParseStart sqlParseState = iota
		sqlParseInStringLiteral
		sqlParseInQuotedIdentifier
		sqlParseInComment
	)

	out := make([]byte, 0, len(sql)+10)

	j := 1
	state := sqlParseStart
	for i := 0; i < len(sql); i++ {
		ch := sql[i]
		switch state {
		case sqlParseStart:
			switch ch {
			case '?':
				out = append(out, '$')
				out = append(out, strconv.Itoa(j)...)
				state = sqlParseStart
				j++
				continue
			case '-':
				if i+1 < len(sql) && sql[i+1] == '-' {
					state = sqlParseInComment
				}
			case '"':
				state = sqlParseInQuotedIdentifier
			case '\'':
				state = sqlParseInStringLiteral
			}
		case sqlParseInStringLiteral:
			if ch == '\'' {
				state = sqlParseStart
			}
		case sqlParseInQuotedIdentifier:
			if ch == '"' {
				state = sqlParseStart
			}
		case sqlParseInComment:
			if ch == '\n' {
				state = sqlParseStart
			}
		}
		out = append(out, ch)
	}

	return string(out)
}

// this type is specially named to match up with the name returned by the
// dialect impl in the sql package.
type __sqlbundle_spanner struct{}

func (p __sqlbundle_spanner) Rebind(sql string) string {
	return sql
}

// this type is specially named to match up with the name returned by the
// dialect impl in the sql package.
type __sqlbundle_sqlite3 struct{}

func (s __sqlbundle_sqlite3) Rebind(sql string) string {
	return sql
}

type __sqlbundle_Literal string

func (__sqlbundle_Literal) private() {}

func (l __sqlbundle_Literal) Render() string { return string(l) }

type __sqlbundle_Literals struct {
	Join string
	SQLs []__sqlbundle_SQL
}

func (__sqlbundle_Literals) private() {}

func (l __sqlbundle_Literals) Render() string {
	var out bytes.Buffer

	first := true
	for _, sql := range l.SQLs {
		if sql == nil {
			continue
		}
		if !first {
			out.WriteString(l.Join)
		}
		first = false
		out.WriteString(sql.Render())
	}

	return out.String()
}

type __sqlbundle_Condition struct {
	// set at compile/embed time
	Name  string
	Left  string
	Equal bool
	Right string

	// set at runtime
	Null bool
}

func (*__sqlbundle_Condition) private() {}

func (c *__sqlbundle_Condition) Render() string {
	// TODO(jeff): maybe check if we can use placeholders instead of the
	// literal null: this would make the templates easier.

	switch {
	case c.Equal && c.Null:
		return c.Left + " is null"
	case c.Equal && !c.Null:
		return c.Left + " = " + c.Right
	case !c.Equal && c.Null:
		return c.Left + " is not null"
	case !c.Equal && !c.Null:
		return c.Left + " != " + c.Right
	default:
		panic("unhandled case")
	}
}

type __sqlbundle_Hole struct {
	// set at compiile/embed time
	Name string

	// set at runtime or possibly embed time
	SQL __sqlbundle_SQL
}

func (*__sqlbundle_Hole) private() {}

func (h *__sqlbundle_Hole) Render() string {
	if h.SQL == nil {
		return ""
	}
	return h.SQL.Render()
}

//
// end runtime support for building sql statements
//

type Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation struct {
	_value_expires_at      time.Time
	_value_storage_node_id []byte
	_value_project_id      []byte
	_value_bucket_name     []byte
	_value_action          uint
	_value_serial_number   []byte
	_set                   bool
}

func (obj *sqlite3Impl) CreateNoReturn_ConsumedSerial(ctx context.Context,
	consumed_serial_expires_at ConsumedSerial_ExpiresAt_Field,
	consumed_serial_storage_node_id ConsumedSerial_StorageNodeId_Field,
	consumed_serial_project_id ConsumedSerial_ProjectId_Field,
	consumed_serial_bucket_name ConsumedSerial_BucketName_Field,
	consumed_serial_action ConsumedSerial_Action_Field,
	consumed_serial_serial_number ConsumedSerial_SerialNumber_Field,
	consumed_serial_settled ConsumedSerial_Settled_Field) (
	err error) {
	__expires_at_val := consumed_serial_expires_at.value()
	__storage_node_id_val := consumed_serial_storage_node_id.value()
	__project_id_val := consumed_serial_project_id.value()
	__bucket_name_val := consumed_serial_bucket_name.value()
	__action_val := consumed_serial_action.value()
	__serial_number_val := consumed_serial_serial_number.value()
	__settled_val := consumed_serial_settled.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO consumed_serials ( expires_at, storage_node_id, project_id, bucket_name, action, serial_number, settled ) VALUES ( ?, ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __expires_at_val, __storage_node_id_val, __project_id_val, __bucket_name_val, __action_val, __serial_number_val, __settled_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *sqlite3Impl) Paged_ConsumedSerial_By_ExpiresAt_Greater(ctx context.Context,
	consumed_serial_expires_at_greater ConsumedSerial_ExpiresAt_Field,
	limit int, start *Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation) (
	rows []*ConsumedSerial, next *Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number, consumed_serials.settled, consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number FROM consumed_serials WHERE consumed_serials.expires_at > ? AND (consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number) > (?, ?, ?, ?, ?, ?) ORDER BY consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number, consumed_serials.settled, consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number FROM consumed_serials WHERE consumed_serials.expires_at > ? ORDER BY consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number LIMIT ?")

	var __values []any
	__values = append(__values, consumed_serial_expires_at_greater.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_expires_at, start._value_storage_node_id, start._value_project_id, start._value_bucket_name, start._value_action, start._value_serial_number, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*ConsumedSerial, next *Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer func() {
				err = errors.Join(err, __rows.Close())
			}()

			var __continuation Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation
			__continuation._set = true

			for __rows.Next() {
				consumed_serial := &ConsumedSerial{}
				err = __rows.Scan(&consumed_serial.ExpiresAt, &consumed_serial.StorageNodeId, &consumed_serial.ProjectId, &consumed_serial.BucketName, &consumed_serial.Action, &consumed_serial.SerialNumber, &consumed_serial.Settled, &__continuation._value_expires_at, &__continuation._value_storage_node_id, &__continuation._value_project_id, &__continuation._value_bucket_name, &__continuation._value_action, &__continuation._value_serial_number)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, consumed_serial)
				next = &__continuation
			}

			if err := __rows.Err(); err != nil {
				return nil, nil, obj.makeErr(err)
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (impl sqlite3Impl) isConstraintError(err error) (constraint string, ok bool) {
	if e, ok := err.(sqlite3.Error); ok {
		if e.Code == sqlite3.ErrConstraint {
			msg := err.Error()
			colon := strings.LastIndex(msg, ":")
			if colon != -1 {
				return strings.TrimSpace(msg[colon:]), true
			}
			return "", true
		}
	}
	return "", false
}

func (obj *sqlite3Impl) deleteAll(ctx context.Context) (count int64, err error) {
	var __res sql.Result
	var __count int64
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM consumed_serials;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count

	return count, nil

}

func (obj *pgxImpl) CreateNoReturn_ConsumedSerial(ctx context.Context,
	consumed_serial_expires_at ConsumedSerial_ExpiresAt_Field,
	consumed_serial_storage_node_id ConsumedSerial_StorageNodeId_Field,
	consumed_serial_project_id ConsumedSerial_ProjectId_Field,
	consumed_serial_bucket_name ConsumedSerial_BucketName_Field,
	consumed_serial_action ConsumedSerial_Action_Field,
	consumed_serial_serial_number ConsumedSerial_SerialNumber_Field,
	consumed_serial_settled ConsumedSerial_Settled_Field) (
	err error) {
	__expires_at_val := consumed_serial_expires_at.value()
	__storage_node_id_val := consumed_serial_storage_node_id.value()
	__project_id_val := consumed_serial_project_id.value()
	__bucket_name_val := consumed_serial_bucket_name.value()
	__action_val := consumed_serial_action.value()
	__serial_number_val := consumed_serial_serial_number.value()
	__settled_val := consumed_serial_settled.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO consumed_serials ( expires_at, storage_node_id, project_id, bucket_name, action, serial_number, settled ) VALUES ( ?, ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __expires_at_val, __storage_node_id_val, __project_id_val, __bucket_name_val, __action_val, __serial_number_val, __settled_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxImpl) Paged_ConsumedSerial_By_ExpiresAt_Greater(ctx context.Context,
	consumed_serial_expires_at_greater ConsumedSerial_ExpiresAt_Field,
	limit int, start *Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation) (
	rows []*ConsumedSerial, next *Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number, consumed_serials.settled, consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number FROM consumed_serials WHERE consumed_serials.expires_at > ? AND (consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number) > (?, ?, ?, ?, ?, ?) ORDER BY consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number, consumed_serials.settled, consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number FROM consumed_serials WHERE consumed_serials.expires_at > ? ORDER BY consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number LIMIT ?")

	var __values []any
	__values = append(__values, consumed_serial_expires_at_greater.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_expires_at, start._value_storage_node_id, start._value_project_id, start._value_bucket_name, start._value_action, start._value_serial_number, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*ConsumedSerial, next *Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer func() {
				err = errors.Join(err, __rows.Close())
			}()

			var __continuation Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation
			__continuation._set = true

			for __rows.Next() {
				consumed_serial := &ConsumedSerial{}
				err = __rows.Scan(&consumed_serial.ExpiresAt, &consumed_serial.StorageNodeId, &consumed_serial.ProjectId, &consumed_serial.BucketName, &consumed_serial.Action, &consumed_serial.SerialNumber, &consumed_serial.Settled, &__continuation._value_expires_at, &__continuation._value_storage_node_id, &__continuation._value_project_id, &__continuation._value_bucket_name, &__continuation._value_action, &__continuation._value_serial_number)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, consumed_serial)
				next = &__continuation
			}

			if err := __rows.Err(); err != nil {
				return nil, nil, obj.makeErr(err)
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (impl pgxImpl) isConstraintError(err error) (constraint string, ok bool) {
	if e, ok := err.(*pgconn.PgError); ok {
		if e.Code[:2] == "23" {
			return e.ConstraintName, true
		}
	}
	return "", false
}

func (obj *pgxImpl) deleteAll(ctx context.Context) (count int64, err error) {
	var __res sql.Result
	var __count int64
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM consumed_serials;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count

	return count, nil

}

func (obj *pgxcockroachImpl) CreateNoReturn_ConsumedSerial(ctx context.Context,
	consumed_serial_expires_at ConsumedSerial_ExpiresAt_Field,
	consumed_serial_storage_node_id ConsumedSerial_StorageNodeId_Field,
	consumed_serial_project_id ConsumedSerial_ProjectId_Field,
	consumed_serial_bucket_name ConsumedSerial_BucketName_Field,
	consumed_serial_action ConsumedSerial_Action_Field,
	consumed_serial_serial_number ConsumedSerial_SerialNumber_Field,
	consumed_serial_settled ConsumedSerial_Settled_Field) (
	err error) {
	__expires_at_val := consumed_serial_expires_at.value()
	__storage_node_id_val := consumed_serial_storage_node_id.value()
	__project_id_val := consumed_serial_project_id.value()
	__bucket_name_val := consumed_serial_bucket_name.value()
	__action_val := consumed_serial_action.value()
	__serial_number_val := consumed_serial_serial_number.value()
	__settled_val := consumed_serial_settled.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO consumed_serials ( expires_at, storage_node_id, project_id, bucket_name, action, serial_number, settled ) VALUES ( ?, ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __expires_at_val, __storage_node_id_val, __project_id_val, __bucket_name_val, __action_val, __serial_number_val, __settled_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *pgxcockroachImpl) Paged_ConsumedSerial_By_ExpiresAt_Greater(ctx context.Context,
	consumed_serial_expires_at_greater ConsumedSerial_ExpiresAt_Field,
	limit int, start *Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation) (
	rows []*ConsumedSerial, next *Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number, consumed_serials.settled, consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number FROM consumed_serials WHERE consumed_serials.expires_at > ? AND (consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number) > (?, ?, ?, ?, ?, ?) ORDER BY consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number, consumed_serials.settled, consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number FROM consumed_serials WHERE consumed_serials.expires_at > ? ORDER BY consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number LIMIT ?")

	var __values []any
	__values = append(__values, consumed_serial_expires_at_greater.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values, start._value_expires_at, start._value_storage_node_id, start._value_project_id, start._value_bucket_name, start._value_action, start._value_serial_number, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*ConsumedSerial, next *Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer func() {
				err = errors.Join(err, __rows.Close())
			}()

			var __continuation Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation
			__continuation._set = true

			for __rows.Next() {
				consumed_serial := &ConsumedSerial{}
				err = __rows.Scan(&consumed_serial.ExpiresAt, &consumed_serial.StorageNodeId, &consumed_serial.ProjectId, &consumed_serial.BucketName, &consumed_serial.Action, &consumed_serial.SerialNumber, &consumed_serial.Settled, &__continuation._value_expires_at, &__continuation._value_storage_node_id, &__continuation._value_project_id, &__continuation._value_bucket_name, &__continuation._value_action, &__continuation._value_serial_number)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, consumed_serial)
				next = &__continuation
			}

			if err := __rows.Err(); err != nil {
				return nil, nil, obj.makeErr(err)
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (impl pgxcockroachImpl) isConstraintError(err error) (constraint string, ok bool) {
	if e, ok := err.(*pgconn.PgError); ok {
		if e.Code[:2] == "23" {
			return e.ConstraintName, true
		}
	}
	return "", false
}

func (obj *pgxcockroachImpl) deleteAll(ctx context.Context) (count int64, err error) {
	var __res sql.Result
	var __count int64
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM consumed_serials;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count

	return count, nil

}

func (obj *spannerImpl) CreateNoReturn_ConsumedSerial(ctx context.Context,
	consumed_serial_expires_at ConsumedSerial_ExpiresAt_Field,
	consumed_serial_storage_node_id ConsumedSerial_StorageNodeId_Field,
	consumed_serial_project_id ConsumedSerial_ProjectId_Field,
	consumed_serial_bucket_name ConsumedSerial_BucketName_Field,
	consumed_serial_action ConsumedSerial_Action_Field,
	consumed_serial_serial_number ConsumedSerial_SerialNumber_Field,
	consumed_serial_settled ConsumedSerial_Settled_Field) (
	err error) {
	__expires_at_val := consumed_serial_expires_at.value()
	__storage_node_id_val := consumed_serial_storage_node_id.value()
	__project_id_val := consumed_serial_project_id.value()
	__bucket_name_val := consumed_serial_bucket_name.value()
	__action_val := consumed_serial_action.value()
	__serial_number_val := consumed_serial_serial_number.value()
	__settled_val := consumed_serial_settled.value()

	var __embed_stmt = __sqlbundle_Literal("INSERT INTO consumed_serials ( expires_at, storage_node_id, project_id, bucket_name, action, serial_number, settled ) VALUES ( ?, ?, ?, ?, ?, ?, ? )")

	var __values []any
	__values = append(__values, __expires_at_val, __storage_node_id_val, __project_id_val, __bucket_name_val, __action_val, __serial_number_val, __settled_val)

	var __stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	obj.logStmt(__stmt, __values...)

	_, err = obj.driver.ExecContext(ctx, __stmt, __values...)
	if err != nil {
		return obj.makeErr(err)
	}
	return nil

}

func (obj *spannerImpl) Paged_ConsumedSerial_By_ExpiresAt_Greater(ctx context.Context,
	consumed_serial_expires_at_greater ConsumedSerial_ExpiresAt_Field,
	limit int, start *Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation) (
	rows []*ConsumedSerial, next *Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation, err error) {

	var __embed_stmt = __sqlbundle_Literal("SELECT consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number, consumed_serials.settled, consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number FROM consumed_serials WHERE consumed_serials.expires_at > ? AND (consumed_serials.expires_at > ? OR (consumed_serials.expires_at = ? AND (consumed_serials.storage_node_id > ? OR (consumed_serials.storage_node_id = ? AND (consumed_serials.project_id > ? OR (consumed_serials.project_id = ? AND (consumed_serials.bucket_name > ? OR (consumed_serials.bucket_name = ? AND (consumed_serials.action > ? OR (consumed_serials.action = ? AND consumed_serials.serial_number > ?)))))))))) ORDER BY consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number LIMIT ?")

	var __embed_first_stmt = __sqlbundle_Literal("SELECT consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number, consumed_serials.settled, consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number FROM consumed_serials WHERE consumed_serials.expires_at > ? ORDER BY consumed_serials.expires_at, consumed_serials.storage_node_id, consumed_serials.project_id, consumed_serials.bucket_name, consumed_serials.action, consumed_serials.serial_number LIMIT ?")

	var __values []any
	__values = append(__values, consumed_serial_expires_at_greater.value())

	var __stmt string
	if start != nil && start._set {
		__values = append(__values,
			start._value_expires_at, start._value_expires_at, start._value_storage_node_id, start._value_storage_node_id, start._value_project_id, start._value_project_id, start._value_bucket_name, start._value_bucket_name, start._value_action, start._value_action, start._value_serial_number,
			limit,
		)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_stmt)
	} else {
		__values = append(__values, limit)
		__stmt = __sqlbundle_Render(obj.dialect, __embed_first_stmt)
	}
	obj.logStmt(__stmt, __values...)

	for {
		rows, next, err = func() (rows []*ConsumedSerial, next *Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation, err error) {
			__rows, err := obj.driver.QueryContext(ctx, __stmt, __values...)
			if err != nil {
				return nil, nil, err
			}
			defer func() {
				err = errors.Join(err, __rows.Close())
			}()

			var __continuation Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation
			__continuation._set = true

			for __rows.Next() {
				consumed_serial := &ConsumedSerial{}
				err = __rows.Scan(&consumed_serial.ExpiresAt, &consumed_serial.StorageNodeId, &consumed_serial.ProjectId, &consumed_serial.BucketName, &consumed_serial.Action, &consumed_serial.SerialNumber, &consumed_serial.Settled, &__continuation._value_expires_at, &__continuation._value_storage_node_id, &__continuation._value_project_id, &__continuation._value_bucket_name, &__continuation._value_action, &__continuation._value_serial_number)
				if err != nil {
					return nil, nil, err
				}
				rows = append(rows, consumed_serial)
				next = &__continuation
			}

			if err := __rows.Err(); err != nil {
				return nil, nil, obj.makeErr(err)
			}

			return rows, next, nil
		}()
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
			return nil, nil, obj.makeErr(err)
		}
		return rows, next, nil
	}

}

func (impl spannerImpl) isConstraintError(err error) (constraint string, ok bool) {
	errcode := spanner.ErrCode(err)
	return "", errcode == codes.AlreadyExists || errcode == codes.OutOfRange || errcode == codes.FailedPrecondition
}

func (obj *spannerImpl) deleteAll(ctx context.Context) (count int64, err error) {
	var __res sql.Result
	var __count int64
	__res, err = obj.driver.ExecContext(ctx, "DELETE FROM consumed_serials;")
	if err != nil {
		return 0, obj.makeErr(err)
	}

	__count, err = __res.RowsAffected()
	if err != nil {
		return 0, obj.makeErr(err)
	}
	count += __count

	return count, nil

}

type Methods interface {
	CreateNoReturn_ConsumedSerial(ctx context.Context,
		consumed_serial_expires_at ConsumedSerial_ExpiresAt_Field,
		consumed_serial_storage_node_id ConsumedSerial_StorageNodeId_Field,
		consumed_serial_project_id ConsumedSerial_ProjectId_Field,
		consumed_serial_bucket_name ConsumedSerial_BucketName_Field,
		consumed_serial_action ConsumedSerial_Action_Field,
		consumed_serial_serial_number ConsumedSerial_SerialNumber_Field,
		consumed_serial_settled ConsumedSerial_Settled_Field) (
		err error)

	Paged_ConsumedSerial_By_ExpiresAt_Greater(ctx context.Context,
		consumed_serial_expires_at_greater ConsumedSerial_ExpiresAt_Field,
		limit int, start *Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation) (
		rows []*ConsumedSerial, next *Paged_ConsumedSerial_By_ExpiresAt_Greater_Continuation, err error)
}

type TxMethods interface {
	Methods

	Rebind(s string) string
	Commit() error
	Rollback() error
}

type txMethods interface {
	TxMethods

	deleteAll(ctx context.Context) (int64, error)
	makeErr(err error) error
}

type DBMethods interface {
	Methods

	Schema() []string
	DropSchema() []string

	Rebind(sql string) string
}

type dbMethods interface {
	DBMethods

	wrapTx(tx *sql.Tx) txMethods
	makeErr(err error) error
}

var sqlite3DriverName = func() string {
	var id [16]byte
	_, _ = rand.Read(id[:])
	return fmt.Sprintf("sqlite3_%x", string(id[:]))
}()

func init() {
	sql.Register(sqlite3DriverName, &sqlite3.SQLiteDriver{
		ConnectHook: sqlite3SetupConn,
	})
}

// SQLite3JournalMode controls the journal_mode pragma for all new connections.
// Since it is read without a mutex, it must be changed to the value you want
// before any Open calls.
var SQLite3JournalMode = "WAL"

func sqlite3SetupConn(conn *sqlite3.SQLiteConn) (err error) {
	_, err = conn.Exec("PRAGMA foreign_keys = ON", nil)
	if err != nil {
		return makeErr(err)
	}
	_, err = conn.Exec("PRAGMA journal_mode = "+SQLite3JournalMode, nil)
	if err != nil {
		return makeErr(err)
	}
	return nil
}

func opensqlite3(source string) (*sql.DB, error) {
	return sql.Open(sqlite3DriverName, source)
}

func openpgx(source string) (*sql.DB, error) {
	return sql.Open("pgx", source)
}

func openpgxcockroach(source string) (*sql.DB, error) {
	// try first with "cockroach" as a driver in case someone has registered
	// some special stuff. if that fails, then try again with "pgx" as
	// the driver.
	db, err := sql.Open("cockroach", source)
	if err != nil {
		db, err = sql.Open("pgx", source)
	}
	return db, err
}

func openspanner(source string) (*sql.DB, error) {
	return sql.Open("spanner", strings.TrimPrefix(source, "spanner://"))
}

func spannerConvertJSON(v any) any {
	if v == nil {
		return spanner.NullJSON{Value: nil, Valid: true}
	}
	if v, ok := v.([]byte); ok {
		return spanner.NullJSON{Value: v, Valid: true}
	}
	if v, ok := v.(*[]byte); ok {
		return &spannerJSON{data: v}
	}
	return v
}

type spannerJSON struct {
	data *[]byte
}

func (s *spannerJSON) Scan(input any) error {
	if input == nil {
		*s.data = nil
		return nil
	}
	if v, ok := input.(spanner.NullJSON); ok {
		if !v.Valid || v.Value == nil {
			*s.data = nil
			return nil
		}

		if str, ok := v.Value.(string); ok {
			bytesVal, err := base64.StdEncoding.DecodeString(str)
			if err != nil {
				return fmt.Errorf("expected base64 from spanner: %w", err)
			}
			*s.data = bytesVal
			return nil
		}

		// "{}" gets returned back as a map[string]interface{} for some reason, so capture any other odd value
		// that comes back and try and marshal it via json.
		bytesVal, err := json.Marshal(v.Value)
		if err != nil {
			return fmt.Errorf("failed to marshal spanner.NullJSON value with type %T to json bytes: %w", v.Value, err)
		}
		*s.data = bytesVal

		return nil
	}
	return fmt.Errorf("unable to decode %T", input)
}

func (obj *spannerImpl) withTx(ctx context.Context, fn func(tx *sql.Tx) error) (err error) {
	for {
		err := obj.withTxOnce(ctx, fn)
		if err != nil {
			if obj.shouldRetry(err) {
				continue
			}
		}
		return err
	}
}

func (obj *spannerImpl) withTxOnce(ctx context.Context, fn func(tx *sql.Tx) error) (err error) {
	tx, err := obj.db.BeginTx(ctx, nil)
	if err != nil {
		return obj.makeErr(err)
	}
	defer func() {
		if err != nil {
			err = obj.makeErr(errors.Join(err, tx.Rollback()))
		} else {
			err = obj.makeErr(tx.Commit())
		}
	}()
	return fn(tx)
}
